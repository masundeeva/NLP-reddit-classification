{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3a793468-bc80-4e23-801c-0ad2d483c5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries import\n",
    "import pandas as pd\n",
    "import praw # needs to be installed first: https://praw.readthedocs.io/en/stable/getting_started/installation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b551ebb-fee6-498c-ab83-9364d67e6372",
   "metadata": {},
   "source": [
    "### Setting up PRAW API\n",
    "I've chosen PRAW API to collect reddit data over PushShift because it worked better with r/office subreddit. For some reason PuchShift wasn't able to query all posts, but worked well with r/DunderMifflin subreddit. \n",
    "For the data collection, I've ended using PRAW to scrape reddit posts from two subreddits: \n",
    "* Dunder Mifflin, that is a fan community dedicated to US TV series \"The Office\"\n",
    "* Office - space to discuss working space related topics, like relationship with coworkers or office supplies.\n",
    "\n",
    "I chose these two subreddits assuming that they would share some parts of vocabulary used in both spaces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e89be662-168b-4aff-a2c9-8caafc6e5dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your credentials here \n",
    "# How to get PRAW credentials: https://www.geeksforgeeks.org/scraping-reddit-using-python/\n",
    "reddit = praw.Reddit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a7e7a4-59cb-40e0-9bf8-1f54af14895d",
   "metadata": {},
   "source": [
    "If you would like to run the notebook on your machine, you have to install PRAW and get your own credentials for PRAW API. You can find guidelines on how to do that in the code cell above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548ee803-1f34-4716-8f68-397ce39160b8",
   "metadata": {},
   "source": [
    "### Downloading Office posts\n",
    "[r/office](https://www.reddit.com/r/office/)\n",
    "> A subreddit to talk about all things office related, from what happened in your office, to stationary supplies, moronic managers, to even a quick question about Microsoft Office! Basically if it's connected to the office in some way, come here to discuss it!\n",
    "* 5.6k Members\n",
    "* Created Sep 9, 2008\n",
    "* Active, 5-10 posts a week recently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9cfeb242-a936-42f1-99ea-cd519a76e09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.geeksforgeeks.org/scraping-reddit-using-python/\n",
    "# Scraping 1000 posts from Office subreddit\n",
    "posts = reddit.subreddit('office').new(limit=1000)\n",
    "# Creating an empty list for each column \n",
    "posts_dict = {'title': [], 'selftext': [], 'author': [],\n",
    "              'id': [], 'score': [],\n",
    "              'comments': [], 'link': [],\n",
    "              'subreddit' : [], 'created': []\n",
    "              }\n",
    "\n",
    "for post in posts:\n",
    "    # Title of a post\n",
    "    posts_dict['title'].append(post.title)\n",
    "     \n",
    "    # Body\n",
    "    posts_dict['selftext'].append(post.selftext)\n",
    "    \n",
    "    # Author \n",
    "    posts_dict['author'].append(post.author)\n",
    "     \n",
    "    # Unique ID\n",
    "    posts_dict['id'].append(post.id)\n",
    "     \n",
    "    # The score \n",
    "    posts_dict['score'].append(post.score)\n",
    "     \n",
    "    # Total number of comments \n",
    "    posts_dict['comments'].append(post.num_comments)\n",
    "     \n",
    "    # URL\n",
    "    posts_dict['link'].append(post.url)\n",
    "    \n",
    "    # Subreddit name\n",
    "    posts_dict['subreddit'].append(post.subreddit)\n",
    "    \n",
    "    # Time of post creation\n",
    "    posts_dict['created'].append(post.created_utc)\n",
    " \n",
    "# Saving the data in a pandas dataframe\n",
    "office_df = pd.DataFrame(posts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bbde14fe-99f7-43a8-a2d7-351815a5f32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving data\n",
    "office_df.to_csv('./data/office_df_original.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763e8b82-2677-4f83-8415-0664a78930c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Downloading Dunder Mifflin posts\n",
    "[r/DunderMifflin](https://www.reddit.com/r/DunderMifflin/)\n",
    "> Why waste time watch many show when one show do trick?\n",
    "* 2.1m Members\n",
    "* Created Jan 8, 2011\n",
    "* Active, 5-10 posts per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b2d945cb-d65c-4c9f-a28d-54c89f76953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to Dunder Mifflin subreddit through a PRAW API\n",
    "posts = reddit.subreddit('DunderMifflin').new(limit=1000)\n",
    "# Creating an empty list for each column \n",
    "posts_dict = {'title': [], 'selftext': [], 'author': [],\n",
    "              'id': [], 'score': [],\n",
    "              'comments': [], 'link': [],\n",
    "              'subreddit' : [], 'created': []\n",
    "              }\n",
    "\n",
    "for post in posts:\n",
    "    # Title of a post\n",
    "    posts_dict['title'].append(post.title)\n",
    "     \n",
    "    # Body\n",
    "    posts_dict['selftext'].append(post.selftext)\n",
    "    \n",
    "    # Author \n",
    "    posts_dict['author'].append(post.author)\n",
    "     \n",
    "    # Unique ID\n",
    "    posts_dict['id'].append(post.id)\n",
    "     \n",
    "    # The score \n",
    "    posts_dict['score'].append(post.score)\n",
    "     \n",
    "    # Total number of comments \n",
    "    posts_dict['comments'].append(post.num_comments)\n",
    "     \n",
    "    # URL\n",
    "    posts_dict['link'].append(post.url)\n",
    "    \n",
    "    # Subreddit name\n",
    "    posts_dict['subreddit'].append(post.subreddit)\n",
    "    \n",
    "    # Time of post creation\n",
    "    posts_dict['created'].append(post.created_utc)\n",
    " \n",
    "# Saving the data in a pandas dataframe\n",
    "DunderMifflin_df = pd.DataFrame(posts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7817ef12-ca3f-43e6-a890-0486ba6a9772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving data\n",
    "DunderMifflin_df.to_csv('./data/DunderMifflin_df_original.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f089a3d-ebf0-40e1-846b-9dbf451c18a8",
   "metadata": {},
   "source": [
    "### Summary\n",
    "Office: \n",
    "* 793 posts\n",
    "* Sunday, April 19, 2020 10:08:23 PM - Sunday, January 15, 2023 5:30:37 PM (GMT)\n",
    "\n",
    "DunderMifflin:\n",
    "* 993 posts\n",
    "* Sunday, January 1, 2023 1:44:36 PM - Monday, January 16, 2023 5:22:40 AM (GMT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
